{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31b21b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pandas import Series, DataFrame\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.api import MNLogit\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "from sklearn import preprocessing\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62483d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ec424e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76782540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51afbefb",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be67e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('STARD/S1_data_kNN_2.csv', index_col='Patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2993558c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = pd.read_csv('STARD/S1_data_kNN_2.csv', index_col='Patient')\n",
    "\n",
    "\n",
    "    #data cleaning\n",
    "    data['L3_treatment'] = data['L3_treatment'].fillna(0)  #define no-treatment in the second stage as treatment 0\n",
    "    data['L3_End_QCTOT'] = data['L3_End_QCTOT'].fillna(data['L3_Int_QCTOT'])  #define the outcome for patients not treated in the second stage\n",
    "\n",
    "    #drop the two rows where we treat someone with QCTOT == 5\n",
    "    data.L3_treatment[1246] = None\n",
    "    data.L3_treatment[3151] = None\n",
    "\n",
    "\n",
    "    data = data.dropna()\n",
    "\n",
    "    data.L2_Int_QCTOT = -data.L2_Int_QCTOT\n",
    "    data.L2_End_QCTOT = -data.L2_End_QCTOT\n",
    "    data.L3_Int_QCTOT = -data.L3_Int_QCTOT\n",
    "    data.L3_End_QCTOT = -data.L3_End_QCTOT\n",
    "    data['dropped'] = None\n",
    "    data['p1'] = None\n",
    "    data['p0'] = None\n",
    "    data['p2'] = None\n",
    "    data['p'] = None\n",
    "    data['weight'] = None\n",
    "    data['Y'] = data.L2_End_QCTOT + data.L3_End_QCTOT\n",
    "    data['Y_impute'] = None\n",
    "\n",
    "    data['A1_L2_Int_QCTOT'] = data.L2_treatment * data.L2_Int_QCTOT\n",
    "    data['A1_L1_slope'] = data.L2_treatment * data.L1_slope\n",
    "    data['A1_L2_preference'] = data.L2_treatment * data.L2_preference\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee6aff",
   "metadata": {},
   "source": [
    "## Compute Propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a6e63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_propensity_weight(data, tau=0):\n",
    "    \n",
    "    features = ['L2_Int_QCTOT','L1_slope','L2_preference']\n",
    "    p1 = LogisticRegression().fit(data[features], data.L2_treatment == 1).predict_proba(data[features])[:,1]\n",
    "    data.p1 = p1*(data.L2_treatment == 1) + (1-p1)*(data.L2_treatment == -1)\n",
    "    \n",
    "    #dropout/stay probability\n",
    "    subdata = data[-data.L2_End_QCTOT > 5]\n",
    "    features = ['L2_Int_QCTOT','L1_slope','L2_preference','L2_treatment', 'L2_End_QCTOT', 'L2_slope', 'A1_L2_Int_QCTOT','A1_L1_slope','A1_L2_preference']\n",
    "    p0 = LogisticRegression(max_iter=1000).fit(subdata[features], 1-subdata['L3_Indicator'])\n",
    "    p0 = p0.predict_proba(data[features])[:,1]\n",
    "    data.p0 = p0*(data.L3_Indicator == 0) + (1-p0)*(data.L3_Indicator == 1)\n",
    "    data.p0[-data.L2_End_QCTOT < 6] = 1\n",
    "    \n",
    "    # the prob of l3 = 1 given l2 = 1\n",
    "    subdata = data[(data.L3_Indicator == 1) & (data.L2_treatment == 1)]\n",
    "    features = ['L2_Int_QCTOT','L1_slope','L2_preference','L2_End_QCTOT', 'L2_slope', 'L3_preference']\n",
    "    p2 = LogisticRegression().fit(subdata[features], subdata.L3_treatment == 1)\n",
    "    p2 = p2.predict_proba(data[features])[:,1]\n",
    "    data.p2 = p2 * (data.L3_treatment == 1) * (data.L2_treatment == 1) + (1-p2) * (data.L3_treatment == -1) * (data.L2_treatment == 1) \n",
    "    data.p2[data.p2==0] = 1\n",
    "    \n",
    "    data['p'] = data.p1 * data.p0 * data.p2\n",
    "    \n",
    "    #clip propensity with tau\n",
    "    data.p = data.p.clip(tau,1)\n",
    "    data.weight = 1/data.p\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee3e3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upweighted_data(tau, random_state, n = 30000):\n",
    "    data = read_data()\n",
    "    data = compute_propensity_weight(data, tau)\n",
    "    data = data.sample(n, replace=True, weights='weight', random_state=random_state)\n",
    "    data.index = np.arange(len(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3122d96e",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058db5f2",
   "metadata": {},
   "source": [
    "## Helper Functions and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb4dda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_reward(data):\n",
    "    Reward = data.Y[data.dropped == False]     \n",
    "    mean_reward = Reward.mean()\n",
    "    return mean_reward/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acfc024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 0\n",
    "d = 3\n",
    "n = 5000\n",
    "n_reps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f0b72a",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6928f284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.437883566138938"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_data()\n",
    "data = compute_propensity_weight(data, tau = 0)\n",
    "sum(((data.L3_treatment != 0) | (data.L3_Int_QCTOT > -6))*data.Y/data.p0)/sum(((data.L3_treatment != 0) | (data.L3_Int_QCTOT > -6))/data.p0) /2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a27ab2f",
   "metadata": {},
   "source": [
    "## DTR Bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d9b94f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forced_pulls_new(q, K, d):\n",
    "    T = 20000\n",
    "    forced_index_minus1minus1 = np.zeros(T, dtype = bool)\n",
    "    forced_index_minus1minus1[0:d] = True\n",
    "    forced_index_11 = np.zeros(T, dtype = bool)\n",
    "    forced_index_11[d:(2*d)] = True\n",
    "    forced_index_1minus1 = np.zeros(T, dtype = bool)\n",
    "    \n",
    "    for i in range(16):\n",
    "        for j in range(q):\n",
    "            if (2**i - 1) * K * q + j > 2*d - 1 and (2**i - 1) * K * q + j < T:\n",
    "                forced_index_minus1minus1[(2**i - 1) * K * q + j] = True\n",
    "            if (2**i - 1) * K * q + q + j> 2*d - 1 and (2**i - 1) * K * q + q + j < T:\n",
    "                forced_index_1minus1[(2**i - 1) * K * q + q + j] = True\n",
    "            if (2**i - 1) * K * q + 2*q + j> 2*d - 1 and (2**i - 1) * K * q + 2*q + j < T:\n",
    "                forced_index_11[(2**i - 1) * K * q + 2*q + j] = True\n",
    "    return forced_index_minus1minus1, forced_index_1minus1, forced_index_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2bda657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta_tilde_linearQ(data):\n",
    "    beta_hat_minus12 = ols('L3_End_QCTOT ~ L3_Int_QCTOT + L2_slope + L3_preference', \n",
    "                           data= data[(data.dropped == False)  & (data.L3_treatment == -1) & (data.forced == True)]).fit() \n",
    "    beta_hat_12 = ols('L3_End_QCTOT ~ L3_Int_QCTOT + L2_slope + L3_preference', \n",
    "                      data= data[(data.dropped == False)  & (data.L3_treatment == 1) & (data.forced == True)]).fit()\n",
    "    \n",
    "    # impute Y values for first stage\n",
    "    data.Y_impute = data.L2_End_QCTOT + (-data.L2_End_QCTOT<=5)*data.L2_End_QCTOT +  ((-data.L2_End_QCTOT>5) & (data.L2_treatment == 1))* np.array([beta_hat_minus12.predict(data), beta_hat_12.predict(data)]).max(axis=0) + ((-data.L2_End_QCTOT>5) & (data.L2_treatment == -1))*beta_hat_minus12.predict(data)\n",
    "    \n",
    "    beta_hat_minus11 = ols('Y_impute ~ L2_Int_QCTOT + L1_slope + L2_preference', \n",
    "                           data= data[(data.dropped == False)  & (data.L2_treatment == -1) & (data.forced == True)]).fit() \n",
    "    beta_hat_11 = ols('Y_impute ~ L2_Int_QCTOT + L1_slope + L2_preference', \n",
    "                      data= data[(data.dropped == False)  & (data.L2_treatment == 1) & (data.forced == True)]).fit()     \n",
    "    return beta_hat_minus11, beta_hat_11, beta_hat_minus12, beta_hat_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a730d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tilde_gap_big(beta_minus1, beta_1, X_i, delta):\n",
    "    if beta_minus1.predict(X_i).iloc[0] - beta_1.predict(X_i).iloc[0] > delta:\n",
    "        return True\n",
    "    if beta_1.predict(X_i).iloc[0] - beta_minus1.predict(X_i).iloc[0] > delta:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3728420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta_linearQ(data):\n",
    "    beta_hat_minus12 = ols('L3_End_QCTOT ~ L3_Int_QCTOT + L2_slope + L3_preference', \n",
    "                           data= data[(data.dropped == False)  & (data.L3_treatment == -1)]).fit() \n",
    "    beta_hat_12 = ols('L3_End_QCTOT ~ L3_Int_QCTOT + L2_slope + L3_preference', \n",
    "                      data= data[(data.dropped == False)  & (data.L3_treatment == 1)]).fit()\n",
    "    \n",
    "    # impute Y values for first stage\n",
    "    data.Y_impute = data.L2_End_QCTOT + (-data.L2_End_QCTOT<=5)*data.L2_End_QCTOT +  ((-data.L2_End_QCTOT>5) & (data.L2_treatment == 1))* np.array([beta_hat_minus12.predict(data), beta_hat_12.predict(data)]).max(axis=0) + ((-data.L2_End_QCTOT>5) & (data.L2_treatment == -1))*beta_hat_minus12.predict(data)\n",
    "    \n",
    "    beta_hat_minus11 = ols('Y_impute ~ L2_Int_QCTOT + L1_slope + L2_preference', \n",
    "                           data= data[(data.dropped == False)  & (data.L2_treatment == -1)]).fit() \n",
    "    beta_hat_11 = ols('Y_impute ~ L2_Int_QCTOT + L1_slope + L2_preference', \n",
    "                      data= data[(data.dropped == False)  & (data.L2_treatment == 1)]).fit()     \n",
    "    return beta_hat_minus11, beta_hat_11, beta_hat_minus12, beta_hat_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7f7b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_optimal_action(beta_minus1, beta_1, X_i):\n",
    "    if beta_minus1.predict(X_i).iloc[0] > beta_1.predict(X_i).iloc[0]:\n",
    "        A = -1\n",
    "    else:\n",
    "        A = 1\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "126bcf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtr_linear_Q(q: int, K: int, d: int, n: int, delta):                \n",
    "    \n",
    "    data['dropped'] = None\n",
    "    data['forced'] = None\n",
    "    n_total = 0 #total number of points\n",
    "    forced_index_minus1minus1, forced_index_1minus1, forced_index_11 = compute_forced_pulls_new(q, K, d)\n",
    "\n",
    "    for i in data.index:\n",
    "    \n",
    "        # compute our chosen arm\n",
    "        if forced_index_11[n_total]:\n",
    "            A_1 = 1\n",
    "            A_2 = 1 \n",
    "            data.forced[i] = True\n",
    "        elif forced_index_minus1minus1[n_total]:\n",
    "            A_1 = -1\n",
    "            A_2 = -1\n",
    "            data.forced[i] = True\n",
    "        elif forced_index_1minus1[n_total]:\n",
    "            A_1 = 1\n",
    "            A_2 = -1\n",
    "            data.forced[i] = True\n",
    "        else:     \n",
    "            data.forced[i] = False\n",
    "            X_i = data[data.index == i]\n",
    "            if tilde_gap_big(beta_tilde_minus11, beta_tilde_11, X_i, delta):\n",
    "                A_1 = choose_optimal_action(beta_tilde_minus11, beta_tilde_11, X_i) \n",
    "            else:\n",
    "                A_1 = choose_optimal_action(beta_hat_minus11, beta_hat_11, X_i) \n",
    "            if - data.L2_End_QCTOT[i] < 6:\n",
    "                A_2 = 0\n",
    "            elif A_1 == -1:\n",
    "                A_2 = -1\n",
    "            else:\n",
    "                if tilde_gap_big(beta_tilde_minus12, beta_tilde_12, X_i, delta/2):  # should we try delta/2?\n",
    "                    A_2 = choose_optimal_action(beta_tilde_minus12, beta_tilde_12, X_i)\n",
    "                else:\n",
    "                    A_2 = choose_optimal_action(beta_hat_minus12, beta_hat_12, X_i)\n",
    "    \n",
    "        # if disagrees, we drop the point; else, we update estimators\n",
    "        if A_1 == data.L2_treatment[i] and A_2 == data.L3_treatment[i]:\n",
    "            data.dropped[i] = False\n",
    "            n_total = n_total + 1         \n",
    "            #estimate hat parameters\n",
    "            if n_total >= 2*d:           \n",
    "                beta_hat_minus11, beta_hat_11, beta_hat_minus12, beta_hat_12 = compute_beta_linearQ(data)  \n",
    "                if data.forced[i]:\n",
    "                    beta_tilde_minus11, beta_tilde_11, beta_tilde_minus12, beta_tilde_12 = compute_beta_tilde_linearQ(data)  \n",
    "        else:\n",
    "            data.dropped[i] = True \n",
    "        \n",
    "        if n_total >= n:\n",
    "            break\n",
    "            \n",
    "    # if we don't get enough samples, we omit this instance\n",
    "    if n_total<n:\n",
    "        print(n_total)\n",
    "        return\n",
    "                \n",
    "    mean_reward = compute_mean_reward(data)\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "q_list = [1,2]\n",
    "delta_list = [10, 20, 50]\n",
    "dtr = {}\n",
    "for i in range(n_reps):\n",
    "    \n",
    "    data = upweighted_data(tau=0, random_state = i)\n",
    "    \n",
    "    for q in q_list:\n",
    "        for delta in delta_list:\n",
    "            cur = dtr_linear_Q(q, K, d, n, delta)\n",
    "            if (q, delta) in dtr:\n",
    "                dtr[(q, delta)].append(cur)\n",
    "            else:\n",
    "                dtr[(q, delta)] = [cur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a81fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10) -7.68006\n",
      "(1, 20) -7.561490000000001\n",
      "(1, 50) -7.552130000000001\n",
      "(2, 10) -7.68764\n",
      "(2, 20) -7.603649999999999\n",
      "(2, 50) -7.547399999999999\n"
     ]
    }
   ],
   "source": [
    "for key in dtr:\n",
    "    print(key, np.mean(dtr[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f3be2",
   "metadata": {},
   "source": [
    "## Epsilon Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6af69491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(eps: int, d:int, n: int, random_state):\n",
    "    data['dropped'] = None\n",
    "    n_total = 0 #total number of points\n",
    "    \n",
    "    # generate random actions\n",
    "    rng1 = np.random.RandomState(random_state*2)\n",
    "    rng2 = np.random.RandomState(random_state*2+1)\n",
    "    temp1 = rng1.binomial(1, eps, size = 30000)\n",
    "    temp2 = rng2.binomial(1, eps, size = 30000)  \n",
    "\n",
    "    for i in data.index:\n",
    "    \n",
    "        # compute our chosen arm\n",
    "        if n_total < d:\n",
    "            A_1 = -1\n",
    "            A_2 = -1        \n",
    "        elif n_total < 2*d:\n",
    "            A_1 = 1\n",
    "            A_2 = 1\n",
    "        elif n_total < 3*d:\n",
    "            A_1 = 1\n",
    "            A_2 = -1\n",
    "        else:    \n",
    "            X_i = data[data.index == i]\n",
    "            A_1 = choose_optimal_action(beta_hat_minus11, beta_hat_11, X_i)\n",
    "            if temp1[i]:\n",
    "                A_1 = -A_1\n",
    "                \n",
    "            if - data.L2_End_QCTOT[i] < 6:\n",
    "                A_2 = 0\n",
    "            elif A_1 == -1:\n",
    "                A_2 = -1\n",
    "            else:\n",
    "                A_2 = choose_optimal_action(beta_hat_minus12, beta_hat_12, X_i)\n",
    "                if temp2[i]:\n",
    "                    A_2 = -A_2\n",
    "    \n",
    "        # if disagrees, we drop the point; else, we update estimators\n",
    "        if A_1 == data.L2_treatment[i] and A_2 == data.L3_treatment[i]:\n",
    "            data.dropped[i] = False\n",
    "            n_total = n_total + 1    \n",
    "            #estimate hat parameters\n",
    "            if n_total >= 2*d:           \n",
    "                beta_hat_minus11, beta_hat_11, beta_hat_minus12, beta_hat_12 = compute_beta_linearQ(data)        \n",
    "        else:\n",
    "            data.dropped[i] = True \n",
    "        \n",
    "        if n_total >= n:\n",
    "            break\n",
    "            \n",
    "    # if we don't get enough samples, we omit this instance\n",
    "    if n_total<n:\n",
    "        return\n",
    "            \n",
    "    mean_reward = compute_mean_reward(data)\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = [0, 0.1, 0.2]\n",
    "eps_greedy = {}\n",
    "for i in range(n_reps):\n",
    "    \n",
    "    data = upweighted_data(tau, random_state = i)\n",
    "                    \n",
    "    for eps in eps_list:\n",
    "        cur = epsilon_greedy(eps, d, n, random_state = i)\n",
    "        if eps in eps_greedy:\n",
    "            eps_greedy[eps].append(cur)\n",
    "        else:\n",
    "            eps_greedy[eps] = [cur] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a49d763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -7.81048\n",
      "0.1 -7.723740000000001\n",
      "0.2 -7.83481\n"
     ]
    }
   ],
   "source": [
    "for key in eps_greedy:\n",
    "    print(key, np.mean(eps_greedy[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca77f4",
   "metadata": {},
   "source": [
    "## LSVI-UCB (Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aae6f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_w(Lambda, temp):\n",
    "    return np.linalg.inv(Lambda) @ temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fea23953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Q(w, phi, beta, Lambda):\n",
    "    temp = w.T @ phi + beta * (phi.T @ np.linalg.inv(Lambda) @ phi)**(1/2)\n",
    "    return temp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e0f11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temp1(a, data, w2_1, w2_minus1, beta, Lambda2_1, Lambda2_minus1):\n",
    "    subdata = data[(data.dropped == False)  & (data.L2_treatment == a)]\n",
    "    temp1 = np.zeros([4,1])\n",
    "    for i in subdata.index:\n",
    "        phi1 = np.array([1, \n",
    "                         subdata.at[i,\"L2_Int_QCTOT\"], \n",
    "                         subdata.at[i,\"L1_slope\"], \n",
    "                         subdata.at[i,\"L2_preference\"]]\n",
    "                       ).reshape(4,1)\n",
    "        phi2 = np.array([1, \n",
    "                         subdata.at[i,\"L3_Int_QCTOT\"], \n",
    "                         subdata.at[i,\"L2_slope\"], \n",
    "                         subdata.at[i,\"L3_preference\"]]\n",
    "                       ).reshape(4,1)\n",
    "        if a == 1:\n",
    "            max_Q = max(compute_Q(w2_1, phi2, beta, Lambda2_1), \n",
    "                    compute_Q(w2_minus1, phi2, beta, Lambda2_minus1)\n",
    "                   )\n",
    "        else:\n",
    "            max_Q = compute_Q(w2_minus1, phi2, beta, Lambda2_minus1)\n",
    "        temp1 += phi1 * (subdata.at[i,\"L2_End_QCTOT\"] + max_Q)\n",
    "    return temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f04f64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_arm(Q_minus1, Q_1):\n",
    "    if Q_minus1 > Q_1:\n",
    "        return -1\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "773b6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_data(tau, random_state):\n",
    "    data = upweighted_data(tau, random_state)\n",
    "    data.L2_Int_QCTOT = data.L2_Int_QCTOT/26\n",
    "    data.L2_End_QCTOT = data.L2_End_QCTOT/26\n",
    "    data.L3_Int_QCTOT = data.L3_Int_QCTOT/26\n",
    "    data.L3_End_QCTOT = data.L3_End_QCTOT/26\n",
    "    data.L1_slope = data.L1_slope/10\n",
    "    data.L2_slope = data.L2_slope/10\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82c29cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsvi_ucb_normalized(lamb, beta, d, n):\n",
    "    \n",
    "    # we include an intercept here, so d should be set to d+1\n",
    "    \n",
    "    data['dropped'] = None\n",
    "    n_total = 0 #total number of points\n",
    "    \n",
    "    Lambda2_1 = lamb * np.identity(d)\n",
    "    Lambda2_minus1 = lamb * np.identity(d)\n",
    "    Lambda1_1 = lamb * np.identity(d)\n",
    "    Lambda1_minus1 = lamb * np.identity(d)\n",
    "    temp2_1 = np.zeros([d,1])\n",
    "    temp2_minus1 = np.zeros([d,1])\n",
    "\n",
    "    \n",
    "    for i in data.index:\n",
    "    \n",
    "        # choose the optimal arm at stage 2\n",
    "        phi2 = np.array([1, \n",
    "                        data.at[i,\"L3_Int_QCTOT\"], \n",
    "                        data.at[i,\"L2_slope\"], \n",
    "                        data.at[i,\"L3_preference\"]]).reshape(d,1)\n",
    "        w2_1 = compute_w(Lambda2_1, temp2_1)\n",
    "        w2_minus1 = compute_w(Lambda2_minus1, temp2_minus1)\n",
    "        if - data.L2_End_QCTOT[i] < 6/26:\n",
    "            A_2 = 0\n",
    "        elif data.L2_treatment[i] == 1:\n",
    "            Q2_1 = compute_Q(w2_1, phi2, beta, Lambda2_1)\n",
    "            Q2_minus1 = compute_Q(w2_minus1, phi2, beta, Lambda2_minus1)\n",
    "            A_2 = optimal_arm(Q2_minus1, Q2_1)\n",
    "        else:\n",
    "            A_2 = -1\n",
    "        \n",
    "            \n",
    "        # if agrees\n",
    "        if A_2 == data.L3_treatment[i]:\n",
    "            # choose the optimal arm at stage 1\n",
    "            phi1 = np.array([1, \n",
    "                             data.at[i,\"L2_Int_QCTOT\"], \n",
    "                             data.at[i,\"L1_slope\"], \n",
    "                             data.at[i,\"L2_preference\"]]).reshape(d,1)\n",
    "            temp1_1 = compute_temp1(1, data, w2_1, w2_minus1, beta, Lambda2_1, Lambda2_minus1)\n",
    "            temp1_minus1 = compute_temp1(-1, data, w2_1, w2_minus1, beta, Lambda2_1, Lambda2_minus1)\n",
    "            w1_1 = compute_w(Lambda1_1, temp1_1)\n",
    "            w1_minus1 = compute_w(Lambda1_minus1, temp1_minus1)\n",
    "            Q1_1 = compute_Q(w1_1, phi1, beta, Lambda1_1)\n",
    "            Q1_minus1 = compute_Q(w1_minus1, phi1, beta, Lambda1_minus1)\n",
    "            A_1 = optimal_arm(Q1_minus1, Q1_1)\n",
    "            \n",
    "            # if agrees, update parameters\n",
    "            if A_1 == data.L2_treatment[i]:\n",
    "                data.dropped[i] = False\n",
    "                n_total = n_total + 1\n",
    "                \n",
    "                Lambda2_1 += (phi2 @ phi2.T) * (A_2 == 1)\n",
    "                Lambda2_minus1 += (phi2 @ phi2.T) * (A_2 == -1)\n",
    "                Lambda1_1 += (phi1 @ phi1.T) * (A_1 == 1)\n",
    "                Lambda1_minus1 += (phi1 @ phi1.T) * (A_1 == -1)\n",
    "                temp2_1 += (phi2 * data.at[i,\"L3_End_QCTOT\"]) * (A_2 == 1)\n",
    "                temp2_minus1 += (phi2 * data.at[i,\"L3_End_QCTOT\"]) * (A_2 == -1)\n",
    "            else:\n",
    "                data.dropped[i] = True  \n",
    "        else:\n",
    "            data.dropped[i] = True \n",
    "        \n",
    "        if n_total >= n:\n",
    "            break\n",
    "            \n",
    "    # if we don't get enough samples, we omit this instance\n",
    "    if n_total<n:\n",
    "        return\n",
    "                \n",
    "    mean_reward = compute_mean_reward(data)\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3553574",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 4 * 2 * (math.log(2* 4 * n ))**(1/2)\n",
    "beta_list = [beta]\n",
    "\n",
    "lsvi = {}\n",
    "for i in range(n_reps):\n",
    "    \n",
    "    data = normalized_data(tau, random_state = i)\n",
    "                    \n",
    "    for beta in beta_list:\n",
    "        cur = lsvi_ucb_normalized(1, beta, 4, n)\n",
    "        if beta in lsvi:\n",
    "            lsvi[beta].append(cur)\n",
    "        else:\n",
    "            lsvi[beta] = [cur] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da9af92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.04197809149967 -8.07054\n"
     ]
    }
   ],
   "source": [
    "for key in lsvi:\n",
    "    print(key, np.mean(lsvi[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceae5d1",
   "metadata": {},
   "source": [
    "## Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9b69aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline(n):\n",
    "    data['dropped'] = None\n",
    "    n_total = 0 #total number of points\n",
    "\n",
    "    #the first period beta's are 0\n",
    "    for i in data.index:    \n",
    "        \n",
    "        if -0.73 - 0.01* data.L2_Int_QCTOT[i] + 0.01*data.L1_slope[i] - 0.67*data.L2_preference[i]>0:\n",
    "            A_1 = 1\n",
    "        else:\n",
    "            A_1 = -1\n",
    "        \n",
    "        if - data.L2_End_QCTOT[i] < 6:\n",
    "            A_2 = 0\n",
    "        elif A_1 == -1:\n",
    "            A_2 = -1\n",
    "        elif -0.18 + 0.01* data.L3_Int_QCTOT[i] - 0.25* data.L2_slope[i] >0 :\n",
    "            A_2 = 1\n",
    "        else:\n",
    "            A_2 = -1\n",
    "       \n",
    "        # if disagrees, we drop the point; else, we update estimators\n",
    "        if A_1 == data.L2_treatment[i] and A_2 == data.L3_treatment[i]:\n",
    "            data.dropped[i] = False\n",
    "            n_total = n_total + 1      \n",
    "        else:\n",
    "            data.dropped[i] = True \n",
    "        \n",
    "        if n_total >= n:\n",
    "            break\n",
    "            \n",
    "    # if we don't get enough samples, we omit this instance\n",
    "    if n_total<n:\n",
    "        return\n",
    "            \n",
    "    mean_reward = compute_mean_reward(data)\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe587c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "off = []\n",
    "for i in range(n_reps):\n",
    "    \n",
    "    data = upweighted_data(tau, random_state = i)\n",
    "    \n",
    "    cur = offline(n)\n",
    "    off.append(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aff36891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.688250000000001"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(off)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
